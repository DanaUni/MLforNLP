{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Files\n",
    "\n",
    "Different sources and tools may make use of different formats to represent information and the output of various tools may not directly correspond. In this course, we will mainly (or even exclusively) work with the conll format. Even within this format, there may be differences in tokenization, class labels used or in the number of columns provided in the output. Depending on what the difference is exactly, you may want to adapt input files or build scripts that can deal with such differences during the process.\n",
    "In this case, we are preparing files that present output of two different tools for evaluation, where the exact annotation scheme differs. We set this up so you can first convert the files, so that they match and then can run evaluation (covered in a different notebook). Originally, both systems had a different tokenization and they both differed from the tokenization used in training and evaluation data. The steps of making sure that the tokens align have already been taken. We left some of the basic functions used as part of this process (e.g. the verification whether tokens align) as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List, Dict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_tokens(conll1: List, conll2: List) -> bool:\n",
    "    '''\n",
    "    Check whether the tokens of two conll files are aligned\n",
    "    \n",
    "    :param conll1: tokens (or full annotations) from the first conll file\n",
    "    :param conll2: tokens (or full annotations) from the first conll file\n",
    "    \n",
    "    :returns boolean indicating whether tokens match or not\n",
    "    '''\n",
    "    for i, row in enumerate(conll1):\n",
    "        row2 = conll2[i]\n",
    "        if row[0] != row2[0]:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_conll_file(conll_file: str, delimiter: str = '\\t'):\n",
    "    '''\n",
    "    Read in conll file and return structured object\n",
    "    \n",
    "    :param conll_file: path to conll_file\n",
    "    :param delimiter: specifies how columns are separated. Tabs are standard in conll\n",
    "    \n",
    "    :returns List of splitted rows included in conll file\n",
    "    '''\n",
    "    conll_rows = []\n",
    "    with open(conll_file, 'r') as my_conll:\n",
    "        for line in my_conll:\n",
    "            row = line.strip(\"\\n\").split(delimiter)\n",
    "            if len(row) == 1:\n",
    "                conll_rows.append([\"\"]*rowlen)\n",
    "            else:\n",
    "                rowlen = len(row)\n",
    "                conll_rows.append(row)\n",
    "    \n",
    "    return conll_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment_okay(conll1: str, conll2: str) -> bool:\n",
    "    '''\n",
    "    Read in two conll files and see if their tokens align\n",
    "    '''\n",
    "    my_first_conll = read_in_conll_file(conll1)\n",
    "    my_second_conll = read_in_conll_file(conll2)\n",
    "\n",
    "    return matching_tokens(my_first_conll, my_second_conll)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predefined_conversions(conversion_file: str) -> Dict:\n",
    "    '''\n",
    "    Read in file with predefined conversions and return structured object that maps old annotation to new annotation\n",
    "    \n",
    "    :param conversion_file: path to conversion file\n",
    "    \n",
    "    :returns object that maps old annotations to new ones\n",
    "    '''\n",
    "    conversion_dict = {}\n",
    "    my_conversions = open(conversion_file, 'r')\n",
    "    conversion_reader = csv.reader(my_conversions, delimiter='\\t')\n",
    "    for row in conversion_reader:\n",
    "        conversion_dict[row[0]] = row[1]\n",
    "    return conversion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_converted_output(conll_rows: List, annotation_identifier: int, conversions: Dict, outputfilename: str, delimiter: str = '\\t'):\n",
    "    '''\n",
    "    Check which annotations need to be converted for the output to match and convert them\n",
    "    \n",
    "    :param conll_rows: rows with conll annotations\n",
    "    :param annotation_identifier: indicator of how to find the annotations in the object (index)\n",
    "    :param conversions: pointer to the conversions that apply. This can be external (e.g. a local file with conversions) or internal (e.g. prestructured dictionary). In case of an internal object, you probably want to add a function that creates this from a local file.\n",
    "    \n",
    "    '''\n",
    "    with open(outputfilename, 'w') as outputfile:\n",
    "        for row in conll_rows:\n",
    "            annotation = row[annotation_identifier]\n",
    "            if annotation in conversions:\n",
    "                row[annotation_identifier] = conversions.get(annotation)\n",
    "            if row[0] == \"\":\n",
    "                outputfile.write(\"\\n\")\n",
    "            else:\n",
    "                outputfile.write(delimiter.join(row)+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_files(conll1: str, conll2: str, column_identifiers: List, conversions: Dict):\n",
    "    '''\n",
    "    Guides the full process of preprocessing files and outputs the modified files.\n",
    "    \n",
    "    :param conll1: path to the first conll input file\n",
    "    :param conll2: path to the second conll input file\n",
    "    :param column_identifiers: object providing the identifiers for target column\n",
    "    :param conversions: path to a file that defines conversions\n",
    "    '''\n",
    "    if alignment_okay(conll1, conll2):\n",
    "        conversions = get_predefined_conversions(conversions)\n",
    "        my_first_conll = read_in_conll_file(conll1)\n",
    "        my_second_conll = read_in_conll_file(conll2)\n",
    "        create_converted_output(my_first_conll, column_identifiers[0], conversions, conll1.replace('.conll','-preprocessed.conll'))\n",
    "        create_converted_output(my_second_conll, column_identifiers[1], conversions, conll2.replace('.conll','-preprocessed.conll'))\n",
    "    else:\n",
    "        print(conll1, conll2, 'do not align')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_NEs(input_list:list, NE_column:int):\n",
    "    '''\n",
    "    Counts the unique NE labels.\n",
    "    \n",
    "    :param input_list: list of the rows of a conll file (output of read_in_conll_file function)\n",
    "    :param NE_column: identifier of the column that contains the NE labels\n",
    "    \n",
    "    :returns dictionary of all classes in the NE_column of the input_list and their count.\n",
    "    '''\n",
    "    NE_counter = Counter()\n",
    "    for line in input_list:\n",
    "        NE_counter.update([line[NE_column]])\n",
    "    return NE_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Change paths\n",
    "The cell below can be used to check if two files align and preprocess these files. This was used for the SpaCy and Stanford conll files.\n",
    "If the file paths are not the same on your device, please replace the path of the input files and their respective NE label column identifiers in the cell below to be able to run the code. If a different conversions file needs to be used, the path to the conversions file can also to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess 2 files (alignment between these files will be checked)\n",
    "# Replace path to input files, their respective column identifiers and the conversions file path here.\n",
    "path_conll1 = '../data/spacy_out.dev.conll' #'../data/stanford_out.dev.conll' for stanford\n",
    "path_conll2 = '../data/conll2003.dev.conll'\n",
    "column_identifiers = [2,3] #[2,3] for spacy & conll2003dev respectively, [3,3] for stanford & conll2003dev respectively.\n",
    "path_conversions = 'settings/conversions.tsv'\n",
    "\n",
    "preprocess_files(path_conll1, path_conll2, column_identifiers, path_conversions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change paths\n",
    "The cell below can be used to preprocess a single file without checking it for alignment with another file.\n",
    "If the file paths are not the same on your device, please replace the path of the input file and its respective NE label column identifier in the cell below to be able to run the code. If a different conversions file needs to be used, the path to the conversions file can also to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess a single file without checking for alignment with another file.\n",
    "# Replace path to input file, its column identifier and the conversions file path here.\n",
    "path_conll = '../data/conll2003.dev.conll'\n",
    "column_identifier = 3\n",
    "path_conversions = 'settings/conversions.tsv'\n",
    "\n",
    "conversions = get_predefined_conversions(path_conversions)\n",
    "conll_rows = read_in_conll_file(path_conll)\n",
    "create_converted_output(conll_rows, column_identifier, conversions, path_conll.replace('.conll','-preprocessed.conll'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file path:\n",
      " ../data/conll2003.dev.conll \n",
      " and \n",
      " ../data/conll2003.dev-preprocessed.conll\n",
      "\n",
      "NE labels before preprocessing:\n",
      " Counter({'O': 42759, '': 3250, 'B-PER': 1842, 'B-LOC': 1837, 'B-ORG': 1341, 'I-PER': 1307, 'B-MISC': 922, 'I-ORG': 751, 'I-MISC': 346, 'I-LOC': 257})\n",
      "\n",
      "NE labels after preprocessing:\n",
      " Counter({'O': 42759, '': 3250, 'PERSON': 3149, 'LOCATION': 2094, 'ORG': 2092, 'MISC': 1268})\n"
     ]
    }
   ],
   "source": [
    "# Show count for each of the NE labels in path_conll file before and after preprocessing.\n",
    "data_raw = read_in_conll_file(path_conll, '\\t')\n",
    "data_preprocessed = read_in_conll_file(path_conll.replace('.conll','-preprocessed.conll'), '\\t')\n",
    "\n",
    "label_counts_raw = count_NEs(data_raw, column_identifier)\n",
    "label_counts_preprocessed = count_NEs(data_preprocessed, column_identifier)\n",
    "\n",
    "print(f\"Using file path:\\n {path_conll} \\n and \\n {path_conll.replace('.conll','-preprocessed.conll')}\")\n",
    "print(\"\\nNE labels before preprocessing:\\n\", label_counts_raw)\n",
    "print(\"\\nNE labels after preprocessing:\\n\", label_counts_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f37b899a14b1e53256e3dbe85dea3859019f1cb8d1c44a9c4840877cfd0e7ef"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
