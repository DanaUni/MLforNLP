{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic System\n",
    "\n",
    "This notebook provides code for implementing a very simple machine learning system for named entity recognition.\n",
    "It uses logistic regression and one feature (the token itself).\n",
    "Links to information about the packages are provided. Your job is to document the code and use it to train a system. You can then use your evaluation code to provide the first basic evaluation of your system.\n",
    "In the next assignment, you can use this as a basis to experiment with more features and more machine learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# If you want to include other modules, you can add them here\n",
    "# Please note the recommendations on using modules in the Programming General Guidelines\n",
    "\n",
    "#recommended resource for examples:\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_labels(trainingfile):\n",
    "    '''\n",
    "    Extracts labels and features from the trainingfile\n",
    "    \n",
    "    :param trainingfile: path to the file with the training data\n",
    "    \n",
    "    :returns a list with a dictionary for each row containing the features for that row, and a list with the target labels\n",
    "    '''\n",
    "    \n",
    "    data = []\n",
    "    targets = []\n",
    "    with open(trainingfile, 'r', encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            components = line.rstrip('\\n').split()\n",
    "            if len(components) > 0:\n",
    "                token = components[0]\n",
    "                feature_dict = {'token':token}\n",
    "                data.append(feature_dict)\n",
    "                #gold is in the last column\n",
    "                targets.append(components[-1])\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(inputfile):\n",
    "    '''\n",
    "    Extracts features from the inputfile\n",
    "    \n",
    "    :param inputfile: path to the inputfile\n",
    "    \n",
    "    :returns a list with a dictionary for each row containing the features for that row\n",
    "    '''\n",
    "    data = []\n",
    "    with open(inputfile, 'r', encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            components = line.rstrip('\\n').split()\n",
    "            if len(components) > 0:\n",
    "                token = components[0]\n",
    "                feature_dict = {'token':token}\n",
    "                data.append(feature_dict)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(train_features, train_targets):\n",
    "    '''\n",
    "    Creates a logistic regression classifier, one-hot encodes the train_features and uses these to fit the model\n",
    "    \n",
    "    :param train_features: a list of dictionaries containing the training features\n",
    "    :param train_targets: a list of the target labels\n",
    "    \n",
    "    :returns the fitted logistic regression model and the one-hot vector\n",
    "    '''\n",
    "    logreg = LogisticRegression(max_iter=500)\n",
    "    vec = DictVectorizer()\n",
    "    features_vectorized = vec.fit_transform(train_features)\n",
    "    model = logreg.fit(features_vectorized, train_targets)\n",
    "    \n",
    "    return model, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(model, vec, inputdata, outputfile):\n",
    "    '''\n",
    "    Extracts the features from the inputdata, one-hot encodes them, then uses those to predict the labels\n",
    "    with the model and write the assigned classes to the outputfile\n",
    "    \n",
    "    :param model: fitted model\n",
    "    :param vec: vectoriser to verctorise the features\n",
    "    :param inputdata: path to the inputfile\n",
    "    :param outputfile: path to the outputfile\n",
    "    '''\n",
    "    features = extract_features(inputdata)\n",
    "    features = vec.transform(features)\n",
    "    predictions = model.predict(features)\n",
    "    outfile = open(outputfile, 'w')\n",
    "    counter = 0\n",
    "    for line in open(inputdata, 'r'):\n",
    "        if len(line.rstrip('\\n').split()) > 0:\n",
    "            outfile.write(line.rstrip('\\n') + '\\t' + predictions[counter] + '\\n')\n",
    "            counter += 1\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    '''\n",
    "    Runs the function to extract the training features and gold labels and use these to create a classifier and classify the data\n",
    "    \n",
    "    :param argv: a list of arguments to indicate the following -> argv[0]: python program used,\n",
    "    argv[1]: path to the trainingfile, argv[2]: path to the inputfile, argv[3]: path to the outputfile\n",
    "    '''\n",
    "    \n",
    "    #a very basic way for picking up commandline arguments\n",
    "    if argv is None:\n",
    "        argv = sys.argv    \n",
    "    \n",
    "    #you can replace the values for these with paths to the appropriate files for now, e.g. by specifying values in argv\n",
    "    #argv = ['mypython_program','','','']\n",
    "    trainingfile = argv[1]\n",
    "    inputfile = argv[2]\n",
    "    outputfile = argv[3]\n",
    "    \n",
    "    training_features, gold_labels = extract_features_and_labels(trainingfile)\n",
    "    ml_model, vec = create_classifier(training_features, gold_labels)\n",
    "    classify_data(ml_model, vec, inputfile, outputfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change paths\n",
    "The cell below can be run to create an output file with the assigned classes from the classifier.\n",
    "Please replace the paths of the files if they are not the same on your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/conll2003.dev-preprocessed.conll\n"
     ]
    }
   ],
   "source": [
    "path_trainingfile = '../data/conll2003.train-preprocessed.conll'\n",
    "path_inputfile = '../data/conll2003.dev-preprocessed.conll'\n",
    "path_outputfile = '../data/conll2003.dev-basic_system-out.conll'\n",
    "\n",
    "\n",
    "args = ['python', path_trainingfile, path_inputfile, path_outputfile]\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
